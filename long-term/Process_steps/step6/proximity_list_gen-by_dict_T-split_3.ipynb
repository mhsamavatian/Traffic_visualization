{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from IPython.display import display\n",
    "from multiprocessing import cpu_count,Pool \n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from orderedset import OrderedSet\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_memory_usage():\n",
    "    print (\"memory log:\")\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(\"%5.2f GB (RSS)\" % (process.memory_info().rss / 2**30))\n",
    "    print(\"%5.2f GB (VMS)\" % (process.memory_info().vms / 2**30))\n",
    "    print(\"%5.2f GB (Used)\" % (psutil.virtual_memory().used / 2**30))\n",
    "    print(\"%5.2f GB (Available)\" % (psutil.virtual_memory().available / 2**30))\n",
    "    print(\"%5.2f GB (Total)\" % (psutil.virtual_memory().total / 2**30))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def distance(data,lat,lng,idx):\n",
    "    fLat = np.radians(data.LocationLat)\n",
    "    fLon = np.radians(data.LocationLng)\n",
    "    sLat = np.radians(lat)\n",
    "    sLon = np.radians(lng)\n",
    "    R = 3958.7564 #mi\n",
    "    #R = 6371000.0 #meters\n",
    "    #R = 6371.0 #km\n",
    "    \n",
    "    dLon = sLon - fLon\n",
    "    dLat = sLat - fLat\n",
    "    a = np.sin(dLat/2.0)**2 + (np.cos(fLat) * np.cos(sLat) * np.power(np.sin(dLon/2.0), 2))\n",
    "    \n",
    "    c = 2.0 * np.arctan2(np.sqrt(a), np.sqrt(1.0 - a))\n",
    "    data['dis2event_'+str(idx)] =  R * c\n",
    "    return data\n",
    "\n",
    "class WithExtraArgs(object):\n",
    "    def __init__(self, func, **args):\n",
    "        self.func = func\n",
    "        self.args = args\n",
    "    def __call__(self, df):\n",
    "        return self.func(df, **self.args)\n",
    "\n",
    "def parjob_long_event_group_T(data,filepath,key_ds):\n",
    "    process_name = str(multiprocessing.current_process())\n",
    "    id = int(process_name.split(',')[0].split('-')[1])\n",
    "    print(\"process \",id,\" started\")\n",
    "    \n",
    "    \n",
    "    ds = pd.read_hdf(filepath,key=key_ds)\n",
    "    print (\"data set is loaded data size is \",ds.shape[0])\n",
    "    traffic_events = ds[ds.Type!='W']\n",
    "    \n",
    "    re_list=[]\n",
    "    raduis=14\n",
    "    total = data.shape[0]\n",
    "    counter=0\n",
    "    event_duration_week_offset = 60*24*60\n",
    "    print (\"partial long event for process \",id,\" is \",data.shape[0])\n",
    "    out_dict={}\n",
    "    \n",
    "    for idx,long_event in data.iterrows():\n",
    "        #(traffic_events.City == long_event.City) &\n",
    "        \n",
    "        temp_df = traffic_events[  (traffic_events.State == long_event.State)  & \n",
    "                                 ((traffic_events.StartTime >= long_event.StartTime- \n",
    "                                     pd.Timedelta(event_duration_week_offset, unit='D')) & \n",
    "                                (traffic_events.EndTime <= long_event.EndTime+\n",
    "                                      pd.Timedelta(event_duration_week_offset, unit='D')))]#time limit\n",
    "        temp_df = distance(temp_df,long_event.LocationLat,long_event.LocationLng,idx)\n",
    "        \n",
    "        \n",
    "        filtered_by_distance = temp_df [(temp_df['dis2event_'+str(idx)] <=raduis) & (temp_df.index != idx) ]\n",
    "        #['dis2event_'+str(idx)] != 0.0)\n",
    "        out_dict[idx] = filtered_by_distance.index\n",
    "        #re_list.append(filtered_by_distance.index)\n",
    "        \n",
    "        counter+=1\n",
    "        if counter%100==0:\n",
    "            print (\"process \", id, counter,\"/\",total, \"long event proccesed \",datetime.datetime.now().time())        \n",
    "    \n",
    "    f = open('dict_files/T_'+'split_3_'+str(id)+'.pkl',\"wb\")\n",
    "    pickle.dump(out_dict,f)\n",
    "    f.close()\n",
    "    return True #re_list\n",
    "\n",
    "def applyParallel_list(pool,data, func, kwargs):\n",
    "    data_split = np.array_split(data,partitions)\n",
    "    data_tag =pool.map(WithExtraArgs(func, **kwargs), data_split)\n",
    "    return data_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = 8#cpu_count() #Number of CPU cores on your system\n",
    "partitions = cores #Define as many partitions as you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "\n",
    "path = \"dict_files/\"\n",
    "dirpath = os.getcwd()\n",
    "dirpath+='/'+path\n",
    "for filename in glob.glob(os.path.join(dirpath, 'T_split_3*')):\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long event size is  13036\n",
      "Traffic long events size is  13036\n",
      "process  1  started\n",
      "process  2  started\n",
      "process  3  started\n",
      "process  4  started\n",
      "process  5  started\n",
      "process  6  started\n",
      "process  7  started\n",
      "process  8  started\n",
      "data set is loaded data size is  15192678\n",
      "data set is loaded data size is  15192678\n",
      "data set is loaded data size is  15192678\n",
      "data set is loaded data size is  15192678\n",
      "data set is loaded data size is  15192678\n",
      "data set is loaded data size is  15192678\n",
      "data set is loaded data size is  15192678\n",
      "partial long event for process  2  is  1630\n",
      "partial long event for process  3  is  1630\n",
      "partial long event for process  1  is  1630\n",
      "partial long event for process  8  is  1629\n",
      "data set is loaded data size is  15192678\n",
      "partial long event for process  7  is  1629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda5/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial long event for process  5  is  1629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda5/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda5/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda5/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial long event for process  4  is  1630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda5/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda5/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda5/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial long event for process  6  is  1629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda5/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process  8 100 / 1629 long event proccesed  20:44:30.267694\n",
      "process  1 100 / 1630 long event proccesed  20:44:37.538621\n",
      "process  3 100 / 1630 long event proccesed  20:44:40.996011\n",
      "process  2 100 / 1630 long event proccesed  20:44:41.039697\n",
      "process  7 100 / 1629 long event proccesed  20:44:47.298550\n",
      "process  4 100 / 1630 long event proccesed  20:45:04.375248\n",
      "process  5 100 / 1629 long event proccesed  20:45:05.692121\n",
      "process  6 100 / 1629 long event proccesed  20:45:09.297820\n",
      "process  8 200 / 1629 long event proccesed  20:46:12.763687\n",
      "process  1 200 / 1630 long event proccesed  20:46:27.681130\n",
      "process  7 200 / 1629 long event proccesed  20:46:35.149275\n",
      "process  2 200 / 1630 long event proccesed  20:46:35.433554\n",
      "process  3 200 / 1630 long event proccesed  20:46:35.496438\n",
      "process  4 200 / 1630 long event proccesed  20:47:19.332071\n",
      "process  5 200 / 1629 long event proccesed  20:47:23.395140\n",
      "process  6 200 / 1629 long event proccesed  20:47:28.285865\n",
      "process  8 300 / 1629 long event proccesed  20:47:56.343695\n",
      "process  1 300 / 1630 long event proccesed  20:48:17.531218\n",
      "process  7 300 / 1629 long event proccesed  20:48:22.356608\n",
      "process  3 300 / 1630 long event proccesed  20:48:29.856965\n",
      "process  2 300 / 1630 long event proccesed  20:48:29.885223\n",
      "process  4 300 / 1630 long event proccesed  20:49:34.524870\n",
      "process  5 300 / 1629 long event proccesed  20:49:40.355649\n",
      "process  8 400 / 1629 long event proccesed  20:49:40.363409\n",
      "process  6 300 / 1629 long event proccesed  20:49:47.126500\n",
      "process  1 400 / 1630 long event proccesed  20:50:08.103765\n",
      "process  7 400 / 1629 long event proccesed  20:50:09.593210\n",
      "process  3 400 / 1630 long event proccesed  20:50:24.588804\n",
      "process  2 400 / 1630 long event proccesed  20:50:24.644285\n",
      "process  8 500 / 1629 long event proccesed  20:51:24.753718\n",
      "process  4 400 / 1630 long event proccesed  20:51:49.378165\n",
      "process  7 500 / 1629 long event proccesed  20:51:56.999482\n",
      "process  5 400 / 1629 long event proccesed  20:51:58.135907\n",
      "process  1 500 / 1630 long event proccesed  20:51:58.274072\n",
      "process  6 400 / 1629 long event proccesed  20:52:06.426572\n",
      "process  3 500 / 1630 long event proccesed  20:52:19.492853\n",
      "process  2 500 / 1630 long event proccesed  20:52:19.499399\n",
      "process  8 600 / 1629 long event proccesed  20:53:27.731525\n",
      "process  7 600 / 1629 long event proccesed  20:53:45.120303\n",
      "process  1 600 / 1630 long event proccesed  20:53:48.112384\n",
      "process  4 500 / 1630 long event proccesed  20:54:05.991390\n",
      "process  3 600 / 1630 long event proccesed  20:54:14.771713\n",
      "process  2 600 / 1630 long event proccesed  20:54:14.808187\n",
      "process  5 500 / 1629 long event proccesed  20:54:15.789648\n",
      "process  6 500 / 1629 long event proccesed  20:54:24.109525\n",
      "process  8 700 / 1629 long event proccesed  20:55:32.148224\n",
      "process  7 700 / 1629 long event proccesed  20:55:33.265444\n",
      "process  1 700 / 1630 long event proccesed  20:55:37.881286\n",
      "process  3 700 / 1630 long event proccesed  20:56:09.322957\n",
      "process  2 700 / 1630 long event proccesed  20:56:10.726804\n",
      "process  4 600 / 1630 long event proccesed  20:56:21.916432\n",
      "process  5 600 / 1629 long event proccesed  20:56:32.788732\n",
      "process  6 600 / 1629 long event proccesed  20:56:41.844278\n",
      "process  7 800 / 1629 long event proccesed  20:57:21.502952\n",
      "process  1 800 / 1630 long event proccesed  20:57:27.536454\n",
      "process  8 800 / 1629 long event proccesed  20:57:36.802096\n",
      "process  3 800 / 1630 long event proccesed  20:58:03.357639\n",
      "process  2 800 / 1630 long event proccesed  20:58:05.156049\n",
      "process  4 700 / 1630 long event proccesed  20:58:37.681024\n",
      "process  5 700 / 1629 long event proccesed  20:58:49.774549\n",
      "process  6 700 / 1629 long event proccesed  20:58:59.452336\n",
      "process  7 900 / 1629 long event proccesed  20:59:09.634576\n",
      "process  1 900 / 1630 long event proccesed  20:59:17.331314\n",
      "process  8 900 / 1629 long event proccesed  20:59:42.129429\n",
      "process  3 900 / 1630 long event proccesed  20:59:57.200236\n",
      "process  2 900 / 1630 long event proccesed  20:59:59.072398\n",
      "process  4 800 / 1630 long event proccesed  21:00:54.025275\n",
      "process  7 1000 / 1629 long event proccesed  21:00:57.526682\n",
      "process  1 1000 / 1630 long event proccesed  21:01:02.938668\n",
      "process  5 800 / 1629 long event proccesed  21:01:08.252949\n",
      "process  6 800 / 1629 long event proccesed  21:01:17.409386\n",
      "process  3 1000 / 1630 long event proccesed  21:01:39.173298\n",
      "process  8 1000 / 1629 long event proccesed  21:01:47.706854\n",
      "process  2 1000 / 1630 long event proccesed  21:01:53.576604\n",
      "process  7 1100 / 1629 long event proccesed  21:02:44.808677\n",
      "process  1 1100 / 1630 long event proccesed  21:02:45.859137\n",
      "process  4 900 / 1630 long event proccesed  21:03:09.945188\n",
      "process  3 1100 / 1630 long event proccesed  21:03:18.767352\n",
      "process  5 900 / 1629 long event proccesed  21:03:23.401401\n",
      "process  6 900 / 1629 long event proccesed  21:03:34.690541\n",
      "process  2 1100 / 1630 long event proccesed  21:03:47.946877\n",
      "process  8 1100 / 1629 long event proccesed  21:03:52.234578\n",
      "process  1 1200 / 1630 long event proccesed  21:04:28.606385\n",
      "process  7 1200 / 1629 long event proccesed  21:04:32.002878\n",
      "process  3 1200 / 1630 long event proccesed  21:04:58.604736\n",
      "process  4 1000 / 1630 long event proccesed  21:05:25.768417\n",
      "process  5 1000 / 1629 long event proccesed  21:05:40.262258\n",
      "process  2 1200 / 1630 long event proccesed  21:05:42.852042\n",
      "process  6 1000 / 1629 long event proccesed  21:05:54.297365\n",
      "process  8 1200 / 1629 long event proccesed  21:05:58.608056\n",
      "process  7 1300 / 1629 long event proccesed  21:06:20.026682\n",
      "process  1 1300 / 1630 long event proccesed  21:06:21.163409\n",
      "process  3 1300 / 1630 long event proccesed  21:06:59.280307\n",
      "process  2 1300 / 1630 long event proccesed  21:07:38.003221\n",
      "process  4 1100 / 1630 long event proccesed  21:07:42.073488\n",
      "process  5 1100 / 1629 long event proccesed  21:07:58.475740\n",
      "process  8 1300 / 1629 long event proccesed  21:08:03.990149\n",
      "process  7 1400 / 1629 long event proccesed  21:08:08.032731\n",
      "process  6 1100 / 1629 long event proccesed  21:08:13.371112\n",
      "process  1 1400 / 1630 long event proccesed  21:08:16.283440\n",
      "process  3 1400 / 1630 long event proccesed  21:09:16.870071\n",
      "process  2 1400 / 1630 long event proccesed  21:09:33.218433\n",
      "process  7 1500 / 1629 long event proccesed  21:09:54.903443\n",
      "process  4 1200 / 1630 long event proccesed  21:10:00.512760\n",
      "process  8 1400 / 1629 long event proccesed  21:10:09.167547\n",
      "process  1 1500 / 1630 long event proccesed  21:10:11.450206\n",
      "process  5 1200 / 1629 long event proccesed  21:10:14.994433\n",
      "process  6 1200 / 1629 long event proccesed  21:10:30.575198\n",
      "process  2 1500 / 1630 long event proccesed  21:11:28.128357\n",
      "process  3 1500 / 1630 long event proccesed  21:11:33.134273\n",
      "process  7 1600 / 1629 long event proccesed  21:11:35.902389\n",
      "process  1 1600 / 1630 long event proccesed  21:12:05.952075\n",
      "process  8 1500 / 1629 long event proccesed  21:12:14.674992\n",
      "process  4 1300 / 1630 long event proccesed  21:12:17.339721\n",
      "process  5 1300 / 1629 long event proccesed  21:12:33.159880\n",
      "process  6 1300 / 1629 long event proccesed  21:12:47.705865\n",
      "process  2 1600 / 1630 long event proccesed  21:13:23.172480\n",
      "process  3 1600 / 1630 long event proccesed  21:13:48.367825\n",
      "process  8 1600 / 1629 long event proccesed  21:14:18.291879\n",
      "process  4 1400 / 1630 long event proccesed  21:14:36.779942\n",
      "process  5 1400 / 1629 long event proccesed  21:14:48.002753\n",
      "process  6 1400 / 1629 long event proccesed  21:15:01.736705\n",
      "process  4 1500 / 1630 long event proccesed  21:16:44.408573\n",
      "process  5 1500 / 1629 long event proccesed  21:17:06.706236\n",
      "process  6 1500 / 1629 long event proccesed  21:17:09.436515\n",
      "process  4 1600 / 1630 long event proccesed  21:18:49.022761\n",
      "process  6 1600 / 1629 long event proccesed  21:19:15.833892\n",
      "process  5 1600 / 1629 long event proccesed  21:19:22.175291\n"
     ]
    }
   ],
   "source": [
    "effective_days_list=[300]\n",
    "for effective_days in effective_days_list:\n",
    "    long_events_ = pd.read_hdf('../../LG.h5',key='T_split_2')\n",
    "    print (\"long event size is \",long_events_.shape[0])\n",
    "    \n",
    "    subset_df = long_events_[long_events_.Type != 'W']\n",
    "    print (\"Traffic long events size is \",subset_df.shape[0])\n",
    "    pool_t = Pool(cores)\n",
    "    Traffic_list = applyParallel_list(pool_t,subset_df,parjob_long_event_group_T,{\"filepath\":'../../data_set_.h5','key_ds':'DS_'+str(effective_days)})\n",
    "    pool_t.close()\n",
    "    pool_t.join()\n",
    "    print (\"done with traffic set\")\n",
    "    print (\"*\"*80)\n",
    "    print_memory_usage()\n",
    "    \n",
    "    #np.save(\"event_list_45_t\"+str(effective_days),Traffic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 [python/3.6]",
   "language": "python",
   "name": "sys_python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
